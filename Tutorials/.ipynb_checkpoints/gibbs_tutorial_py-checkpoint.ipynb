{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gibbs measure over a grid tutorial\n",
    "\n",
    "This notebook illustrates the knockoff construction for a Gibbs measure across a grid with probability mass function\n",
    "$$p(X) = \\frac{1}{Z(\\beta_0)} \\exp\\left(-\\beta_0\\sum_{\\substack{s, t \\in \\mathcal I \\\\\\|s-t\\|_1=1}}(x_s-x_t)^2 \\right),\\quad\\mathcal I = \\{(i_1,i_2) : 1\\le i_1,i_2 \\le d\\}.$$\n",
    "Each variable has support $\\{1,\\dots,K\\}$ where $K$ is a positive integer.  Section 5.2.4 of the accompanying paper presents a large set of simulation results in this setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple-try Metropolis\n",
    "\n",
    "For large $K$, Multiple-try Metropolis (Section 3.3 of the paper) gives the most efficient sampler for this class of distributions. We demonstrate this technique below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "import seaborn as sns\n",
    "\n",
    "%run ../Gibbs-grid/Gibbs_MTM #load the Gibbs simulation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#simulation parameters\n",
    "d = 5\n",
    "p = d * d #total number of variables\n",
    "K = 5 # support size\n",
    "beta = 0.2 #interaction strength\n",
    "numsamples = 100\n",
    "\n",
    "#algorithm parameters\n",
    "N_gibbs = 100 #number of iterations for the initial Gibbs sampler\n",
    "gamma = .99 \n",
    "half_num_try = 1 #half the number of proposals\n",
    "step_size = 1 #propsal size\n",
    "max_width = 2 #slicing width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a Gibbs sampler to generate samples from the model, and then generate a corresponding knockoff with the function `SCEP_MH_Gibbs_slice`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time per observation + knockoff (seconds): 0.348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100, 50)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigmatrix = np.zeros([numsamples,2*p]) #store simulation results\n",
    "\n",
    "#generate each observation and knockoff\n",
    "start = time.time()\n",
    "for i in range(numsamples):\n",
    "    # sample a single observation\n",
    "    x_obs = Gibbs_sampler(d, d, K, beta, N = N_gibbs)\n",
    "    \n",
    "    #generate a knockoff for the observation\n",
    "    xk = SCEP_MH_Gibbs_slice(k1 = d, k2 = d, K = K, \n",
    "        beta = beta, x_obs = x_obs,  gamma = gamma, \n",
    "        half_num_try = half_num_try, step_size = step_size, \n",
    "        max_width = max_width)\n",
    "    bigmatrix[i,:] = np.append(np.reshape(x_obs, p), np.reshape(xk, p))\n",
    "end = time.time()\n",
    "\n",
    "print(\"Average time per observation + knockoff (seconds): \" + \\\n",
    "      '%.3f'%((end - start) / numsamples))\n",
    "    \n",
    "np.shape(bigmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-0.34821'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'%.5f'%((start - end) / numsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3482085299491882"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(start - end) / numsamples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate the quality of these knocokffs by computing the average correlation between $X_{i,j}$ and $\\tilde{X}_{i,j}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6861175462821908"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cors = []\n",
    "for j in range(p):\n",
    "    cors += [np.corrcoef(bigmatrix[:, j].T, \n",
    "                         bigmatrix[:, j + p].T)[0,1]]\n",
    "np.mean(cors)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diagnostics: checking means and covariances\n",
    "\n",
    "As a basic diagnostic, we check that each coordinate has mean and the the empirical covariance matrices of $X$ and $\\tilde{X}$ are close. As the number of samples increases, the empirical covariance of $X$ and $\\tilde{X}$ will converge to the same population covariance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18\n",
      "2.11\n"
     ]
    }
   ],
   "source": [
    "#largest mean of the columns of X\n",
    "print(np.max(np.abs(np.mean(bigmatrix[:, 0:p], axis = 0))))\n",
    "#largest mean of the columns of Xk\n",
    "print(np.max(np.abs(np.mean(bigmatrix[:, p:(2*p)], axis = 0))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
